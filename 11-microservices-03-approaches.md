# Домашнее задание к занятию «Микросервисы: подходы» - Леонид Хорошев

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Наиболее очевидное решение для подобного проекта - построение инфраструктуры на основе сервисов, предоставляемых GitLab. На старте проекта целесообразно развернуть инфраструктуру на базе готового облачного решения (например Яндекс облако) - Managed GitLab. Очевидные плюсы такого решения:
- легкость первоначальной настройки такого решения (Яндекс предоставляет исчерпывающие инструкции по созданию инфраструктуры, в том числе с помощью terraform, что позволяет гибко варьировать требуемые параметры с помощью кода и следовать принципу - "инфраструктура как код");
- возможность масштабирования при развитии проекта (ресурсы и количевто виртуальных машин, на которых установлены раннеры для нашего CI/CD конвейера также можно легко варьировать при помощи terraform).

Gitlab предоставляет свою систему контроля версий, которой уместно пользоваться при разработке проекта. В случае необходимости поделиться кодом с более широкой аудиторией (другими командами или выложить в открытый доступ), также доступна удобная [интеграция](https://docs.gitlab.com/ee/user/project/import/github.html) с Github.

Запуск сборки как по событию, так и по кнопке с указанием параметров возможен через сервис GitLAb CI, там же удобно хранить различные шаблоны и конфигурации, а также существует своя система контроля качества кода (то есть не требуется интеграция с Sonarcube, как в случае, например с Jenkins).

Для хранения секретный данных в GitLab также предусмотрено отдельное [хранилище](https://docs.gitlab.com/ee/security/password_storage.html).

В целом при определении наиболее удобного решения под конкретный проект можно воспользоваться сравнительной таблицей:

| Характеристика |	Jenkins	| GitLab CI/CD |
|----------------|----------|--------------|
| Открытый или закрытый код	| Открытый код |	Открытый код |
| Уникальные особенности |	Поддержка плагинов |	Глубокая интеграция в систему управления версиями |
| Поддержка |	Отсутствует |	Имеется |
| Установка и настройка |	Сложностей не вызывают |	Сложностей не вызывают |
| Самостоятельное развёртывание системы | Это — единственный вариант использования системы |	Поддерживается |
| Создание CI/CD-конвейеров	Поддерживается | используется Jenkins Pipeline |	Поддерживается |
| Мониторинг производительности приложений |	Отсутствует |	Имеется |
| Экосистема |	Существует более 1000 плагинов |	Система развивается в рамках GitLab |
| API |	Поддерживает развитую систему API |	Предлагает API для более глубокой интеграции в проекты |
| Поддержка JavaScript |	Имеется |	Имеется |
| Интеграция с другими инструментами |	Поддерживается интеграция с другими инструментами и платформами (Slack, GitHub) |	Множество средств для интеграции со сторонними системами, в частности — с GitHub и Kubernetes |
| Контроль качества кода |	Поддерживается — с помощью плагина SonarQube и других плагинов |	Поддерживается |

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Тут наиболее очевидный вариант - стек ELK. Он достаточно прост в [настройке](https://github.com/netology-code/mnt-homeworks/blob/MNT-video/10-monitoring-04-elk/help/docker-compose.yml) и состоит из следующих сервисов:
 - Elasticsearch (хранение и поиск данных);
 - Logstash (конвеер для обработки, фильтрации и нормализации логов);
 - Kibana (интерфейс для удобного поиска и администрирования).

Из-за требований к вычислительным ресурсам я бы рекомендовал запускать Elasticsearch на отдельной ноде. Для сбора логов с микросервисов на ноды с микросервисами устанавливается Filebeat (агент сбора данных).

Filebeat может направлять данные непосредственно в Elasticsearch, однако лучше их (логи) пропускать через Logstash, где можно отфильтровать информацию и сделать логи более читаемыми. При настройке сбора логов есть различные варианты сервисов, например вменсто Logstash можно использовать Vector, который также может направлять логи в Elasticserach в удобочитаемом формате (данная схема как раз используется в задании 4 данной домашней работы), однако на мой субъективный взгляд Vector чуть сложнее в настройке.

Данные логов отображаются в графическом веб-интерфейсе Kibana, где их вид можно настраивать, устанавливать различные алерты и т.д.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Под данную задачу одинаково подходят два решения:
- Zabbix;
- Prometheus и Grafana (используется как веб интерфейс, так как в отличие от Zabbix у Prometheus отсутствует собственная визуализация данных).

Zabbix проще в установке и настройке - на нашем проекте можно настроить Zabbix-сервер на отдельном хосте и подключить к нему Zabbix-агентов с каждого микросервиса. Zabbix устанавливается «из коробки» и адаптируется ко всем видам ПО, а для Prometheus понадобится установка бинарника, юнита в Systemd или скрипта для автоматического запуска. Zabbix - универсальная система мониторинга, которая объединяет в себе вообще всю инфраструктуру, например в отличие от Prometheus им можно мониторить даже логи (лучше конечно мониторить логи в Elasticsearch, как описано в вопросе 2 данного домашнего задания, но для упрощения мониторинга на совсем небольших проектов можно замкнуть всю системы мониторинга на Zabbix). Также имеется возможность  подключить  внешние метрики через API.

Несмотря на то, что Prometheus сложнее в установке, и для полноценной его работы необходимо также установить и настроить Alertmanager и Grafana, на проекте он может быть более эффективен за счет того, что использует  модель pull для сбора метрик (активно запрашивает данные у наших микросервисов). Такой подход может быть более удобным в случае ограниченности наших вычислительных ресурсов (в модели pull сервер мониторинга контролирует процесс сбора данных, что позволяет снизить нагрузку на сеть и целевые сервисы. Поскольку целевые системы не отправляют данные активно, они могут работать более эффективно).

Еще один очевидный плюс Prometheus - он легко масштабируется как вертикально (добавление ресурсов на сервере Prometheus), так и горизонтально (добавление дополнительных экземпляров Prometheus). Он также расширяем с помощью экспортеров, которые позволяют собирать метрики из различных систем и приложений (в нашем случае это может быть полезно, так как требуется мониторить различные специфичные  метрики наших сервисов, которых может не быть в Zabbix). 

В результате при всем удобстве Zabbix, для мониторинга нашего проекта я бы претпочел стек из Prometheus, Grafana и Alertmanager, так как в перспективе при росте проекта это может быть более эффективным решением за счет возможностей масштабирования и более тонкой настройки метрик, кроме того по условиям задания наша система мониторинга должна позволять делать запросы и агрегировать информацию, а для этой цели идеально подходит Prometheus Query Language (в Zabbix свой язык запросов отсутствует).
  
## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

Для решения данной задачи, добавим в наш `docker-compose.yaml` в блок `services` контейнеры `Vector`, `ElasticSearch` и `Kibana`.
```
  vector:
    image: timberio/vector:latest
    depends_on:
      - storage
      - uploader
      - security
    volumes:
      - ./vector/config:/etc/vector
    command: ["-c", "/etc/vector/vector.toml"]

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.0
    ports:
      - "8081:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    depends_on:
      - elasticsearch
```

В конфигурационный файл нашего Api Gateway также внесем изменения:
- добавим блок upstream vector для проксирования запросов к сервису Vector, который будет собирать и передавать логи:
```
upstream vector {
    server vector:24224;
}
```
- добавим блок location для проксирования запросов к сервису Vector:
```
location /logs {
    proxy_pass http://vector;
}
```
- аналогично пропишем в нашем конфигурационном файле блоки upstream `Elasticsearch` (для проксирования запросов к сервису ElasticSearch) и `Kibana` (для проксирования запросов к сервису Kibana):
```
upstream elasticsearch {
    server elasticsearch:9200;
}

upstream kibana {
    server kibana:5601;
}
```
- также добавим блок location для наших новых сервисов
```
location /elasticsearch {
    proxy_pass http://elasticsearch;
}

location /kibana {
    proxy_pass http://kibana;
}
```

Пробуем запустить контейнеры
```
docker compose up
```

Получаем ошибку:

![Alt_text](https://github.com/LeonidKhoroshev/micros-homeworks/blob/main/11-microservices-02-principles/screenshots/micros4.png)

Возвращаемся к домашней работе по соответствующей [теме](https://github.com/LeonidKhoroshev/mnt-homeworks/blob/MNT-video/10-monitoring-04-elk/README.md) и корректируем наш `docker-compose` файл, заменив в конфигурации заблокированные образы на рабочие:
```
elasticsearch:
    image: elasticsearch:8.7.0

  kibana:
    image: kibana:8.7.0
```

Повторяем эксперимент
```
sysctl -w vm.max_map_count=262144
docker compose up
```

В этот раз ошибка со стартом Vector, так как для него необходимо создать отдельный конфигурационный файл `vector/config/yml`
```
sources:
  default:
    type: stdin

sinks:
  es:
    type: elasticsearch
    endpoint: "http://elasticsearch:9200"
    inputs:
      - default
```

Пробуем еще раз
```
docker compose up
docker ps -a
```

![Alt_text](https://github.com/LeonidKhoroshev/micros-homeworks/blob/main/11-microservices-02-principles/screenshots/micros5.png)

### Результат выполнения: 

[docker compose файл](https://github.com/LeonidKhoroshev/micros-homeworks/blob/main/11-microservices-02-principles/docker-compose.yaml), запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.

![Alt_text](https://github.com/LeonidKhoroshev/micros-homeworks/blob/main/11-microservices-02-principles/screenshots/micros6.png)



## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

Добавим в наш `docker-compose.yaml` образы Prometheus и Grafana
```
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus-data:/etc/prometheus
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD="qwerty123456"
```

Создадим конфигурационный файл для Prometheus
```
mkdir prometheus
nano prometheus/prometheus.yml

scrape_configs:
  - job_name: 'security'
    static_configs:
      - targets: ['security:3000/metrics']

  - job_name: 'uploader'
    static_configs:
      - targets: ['uploader:3000/metrics']

  - job_name: 'minio'
    static_configs:
      - targets: ['storage:9000/minio/v2/metrics/cluster']
```

В конфигурационный файл нашего API Gateway `nginx.conf` добавляем следующие блоки:
```
location /metrics/security {
    proxy_pass http://security/metrics;
}

location /metrics/uploader {
    proxy_pass http://uploader/metrics;
}

location /metrics/minio {
    proxy_pass http://minio/minio/v2/metrics/cluster;
}
```

Запускаем и проверяем статус контейнеров 
```
docker compose up
docker ps -a
```

![Alt_text](https://github.com/LeonidKhoroshev/micros-homeworks/blob/main/11-microservices-02-principles/screenshots/micros7.png)

Все работает, однако вход в веб-интерфейс Grafana стал возможен только после замены пароля в контейнере вручную
```
docker-compose exec grafana grafana-cli admin reset-admin-password qwerty123456
```

![Alt_text](https://github.com/LeonidKhoroshev/micros-homeworks/blob/main/11-microservices-02-principles/screenshots/micros8.png)

Далее в веб-интерфейсе Grafana добавляем источник данных (собственно наш Prometheus)

![Alt_text](https://github.com/LeonidKhoroshev/micros-homeworks/blob/main/11-microservices-02-principles/screenshots/micros9.png)


### Результат выполнения: 

[docker compose](https://github.com/LeonidKhoroshev/micros-homeworks/tree/main/11-microservices-02-principles) файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.


---
