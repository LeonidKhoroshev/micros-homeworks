# Домашнее задание к занятию «Микросервисы: подходы» - Леонид Хорошев

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

Для решения данной задачи, добавим в наш `docker-compose.yaml` в блок `services` контейнеры `Vector`, `ElasticSearch` и `Kibana`.
```
  vector:
    image: timberio/vector:latest
    depends_on:
      - storage
      - uploader
      - security
    volumes:
      - ./vector/config:/etc/vector
    command: ["-c", "/etc/vector/vector.toml"]

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.0
    ports:
      - "8081:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    depends_on:
      - elasticsearch
```

В конфигурационный файл нашего Api Gateway также внесем изменения:
- добавим блок upstream vector для проксирования запросов к сервису Vector, который будет собирать и передавать логи:
```
upstream vector {
    server vector:24224;
}
```
- добавим блок location для проксирования запросов к сервису Vector:
```
location /logs {
    proxy_pass http://vector;
}
```
- аналогично пропишем в нашем конфигурационном файле блоки upstream `Elasticsearch` (для проксирования запросов к сервису ElasticSearch) и `Kibana` (для проксирования запросов к сервису Kibana):
```
upstream elasticsearch {
    server elasticsearch:9200;
}

upstream kibana {
    server kibana:5601;
}
```
- также добавим блок location для наших новых сервисов
```
location /elasticsearch {
    proxy_pass http://elasticsearch;
}

location /kibana {
    proxy_pass http://kibana;
}
```

Пробуем запустить контейнеры
```
docker compose up
```

Получаем ошибку:

![Alt_text](https://github.com/LeonidKhoroshev/micros-homeworks/blob/main/11-microservices-02-principles/screenshots/micros4.png)

Возвращаемся к домашней работе по соответствующей [теме[]()](https://github.com/LeonidKhoroshev/mnt-homeworks/blob/MNT-video/10-monitoring-04-elk/README.md) и корректируем наш `docker-compose` файл, заменив в конфигурации заблокированные образы на рабочие:
```
elasticsearch:
    image: elasticsearch:8.7.0

  kibana:
    image: kibana:8.7.0
```

Повторяем эксперимент
```
sysctl -w vm.max_map_count=262144
docker compose up
```

В этот раз ошибка со стартом Vector, так как для него необходимо создать отдельный конфигурационный файл `vector/config/yml`
```
sources:
  default:
    type: stdin

sinks:
  es:
    type: elasticsearch
    endpoint: "http://elasticsearch:9200"
    inputs:
      - default
```

Пробуем еще раз
```
docker compose up
docker ps -a
```


### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

![Alt_text](https://github.com/LeonidKhoroshev/micros-homeworks/blob/main/11-microservices-02-principles/screenshots/micros5.png)

---
